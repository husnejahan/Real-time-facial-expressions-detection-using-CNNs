{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "np.random.seed(1234)\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from numpy import genfromtxt\n",
    "from lasagne.layers import batch_norm ,dropout,DenseLayer\n",
    "\n",
    "conv = lasagne.layers.Conv2DLayer\n",
    "pool = lasagne.layers.MaxPool2DLayer\n",
    "NUM_EPOCHS = 500\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.001\n",
    "DIM = 48\n",
    "DATA_SIZE = 35887\n",
    "NUM_CLASSES = 10\n",
    "FILE_NAME = \"fer2013/fer2013.csv\"\n",
    "print('run successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters in model: 2388970\n",
      "run successfully\n"
     ]
    }
   ],
   "source": [
    "def build_model(input_width, input_height, output_dim):\n",
    "    ini = lasagne.init.HeUniform(gain='relu')\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 1, input_width, input_height),)\n",
    "    \n",
    "    class_l1 = batch_norm(conv(\n",
    "        l_in,\n",
    "        num_filters=32,pad='same',\n",
    "        filter_size=(3, 3),\n",
    "        #filter_size=(5, 5),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    ))\n",
    "    class_d0 = dropout(class_l1,p=0.3)\n",
    "    \n",
    "    class_l2 = batch_norm(conv(\n",
    "        class_d0,\n",
    "        num_filters=32,pad='same',\n",
    "        filter_size=(3, 3),\n",
    "        #filter_size=(5, 5),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    ))\n",
    "    class_d1 = dropout(class_l2,p=0.3)\n",
    "    \n",
    "    \n",
    "    class_l3 = batch_norm(conv(\n",
    "        class_d1,\n",
    "        num_filters=32,pad='same',\n",
    "        filter_size=(3, 3),\n",
    "        #filter_size=(5, 5),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    ))\n",
    "    class_d2 = dropout(class_l3,p=0.35)\n",
    "    \n",
    "    \n",
    "    class_l4 = batch_norm(conv(\n",
    "        class_d2,\n",
    "        num_filters=32,pad='same',\n",
    "        filter_size=(3, 3),\n",
    "        #filter_size=(5, 5),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    ))\n",
    "    class_d3 = dropout(class_l4,p=0.2)   \n",
    "    #class_l5 = pool(class_l4, pool_size=(2, 2))\n",
    "    \n",
    "    \n",
    "    class_l1_dens = batch_norm(DenseLayer(\n",
    "        class_d3,\n",
    "        num_units=32,\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    )) \n",
    "    class_d1_dens = dropout(class_l1_dens,0.3)\n",
    "    \n",
    "    class_l2_dens = batch_norm(DenseLayer(\n",
    "        class_d1_dens,\n",
    "        num_units=32,\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    )) \n",
    "    class_d2_dens = dropout(class_l2_dens,p=0.2)\n",
    "    \n",
    "    l_out = DenseLayer(\n",
    "        class_d2_dens,\n",
    "        num_units=output_dim,\n",
    "        nonlinearity=lasagne.nonlinearities.softmax,\n",
    "        W=ini,\n",
    "    )\n",
    "    return l_out\n",
    "\n",
    "model= build_model(DIM, DIM, NUM_CLASSES)\n",
    "print(\"number of parameters in model: %d\" % lasagne.layers.count_params(model, trainable=True))\n",
    "print('run successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run successfully\n"
     ]
    }
   ],
   "source": [
    "#Setting up the graph in theano\n",
    "sym_x = T.tensor4('sym_x') # a symbolic variable, this is now a 4-D tensor.\n",
    "sym_t = T.ivector('sym_t') # a symbolic variable taking on the value of the target batch.\n",
    "\n",
    "# Retrieve network output\n",
    "train_out = lasagne.layers.get_output(model, sym_x, deterministic=False)\n",
    "eval_out = lasagne.layers.get_output(model, sym_x, deterministic=True)\n",
    "\n",
    "# Retrieve list of all trainable parameters in the network.\n",
    "all_params = lasagne.layers.get_all_params(model, trainable=True)\n",
    "\n",
    "# add weight decay\n",
    "all_layers = lasagne.layers.get_all_layers(model)\n",
    "l2_penalty = lasagne.regularization.regularize_layer_params(all_layers, lasagne.regularization.l2) * 0.001\n",
    "\n",
    "\n",
    "#reg2 = lasagne.regularization.l2(train_out)\n",
    "#reg = lasagne.regularization.l1( train_out )\n",
    "cost = lasagne.objectives.categorical_crossentropy(train_out+1e-8, sym_t).mean()\n",
    "\n",
    "# Let Theano do its magic and get all the gradients we need for training\n",
    "all_grads = T.grad(cost, all_params)\n",
    " \n",
    "# Set the update function for parameters \n",
    "# you might wan't to experiment with more advanded update schemes like rmsprob, adadelta etc.\n",
    "sh_lr = theano.shared(lasagne.utils.floatX(LEARNING_RATE))\n",
    "\n",
    "Updates = lasagne.updates.adam(all_grads, all_params, learning_rate=sh_lr)\n",
    "\n",
    "f_eval = theano.function([sym_x],eval_out, on_unused_input='warn')\n",
    "\n",
    "f_train = theano.function([sym_x, sym_t],[cost],updates=Updates, on_unused_input='warn')\n",
    "print('run successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run successfully\n"
     ]
    }
   ],
   "source": [
    "with np.load('weights.npz') as f:\n",
    "    param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "lasagne.layers.set_all_param_values( model, param_values)\n",
    "print('run successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c077fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "# (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "fig = plt.figure()\n",
    "cv2.destroyAllWindows()\n",
    "cap = cv2.VideoCapture(0)\n",
    "ii= 0\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ii == 10:\n",
    "        ii=0\n",
    "    else:\n",
    "        ii +=1\n",
    "        continue\n",
    "    #start here\n",
    "    img = frame\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    facelocs = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    faces = np.ndarray(shape=(1, 48*48), dtype=np.uint8)\n",
    "    for (x,y,w,h) in facelocs:\n",
    "        face = gray[y:y + h, x: x + w]\n",
    "        face = cv2.resize(face, (48, 48), interpolation = cv2.INTER_CUBIC)\n",
    "        face = np.array(face)\n",
    "        face = np.reshape(face, 48*48)\n",
    "        faces = np.vstack((faces, face))\n",
    "    faces = np.delete(faces, 0, 0)\n",
    "    if faces.shape[0]!=0: \n",
    "        modes = np.array(['emojis/happy.png','emojis/disgust.png','emojis/fear.png','emojis/happy.png',\n",
    "                      'emojis/sad.png','emojis/surprised.png','emojis/neutral.png'])\n",
    "        faces = faces.reshape((faces.shape[0], 1, DIM, DIM))\n",
    "        #print faces.shape\n",
    "        net_out = f_eval(faces)   \n",
    "        preds = np.argmax(net_out, axis=-1)\n",
    "        i = 0\n",
    "        for (x, y, w, h) in facelocs:\n",
    "            emoji_r = cv2.cvtColor(cv2.imread(modes[preds[i]], -1), cv2.COLOR_BGRA2RGBA)\n",
    "            emoji = cv2.resize(emoji_r, (w, h), interpolation = cv2.INTER_CUBIC)\n",
    "            i+=1\n",
    "            for c in range(0,3):\n",
    "                img[y:y + h, x:x+w, c] = emoji[:,:,c] * (emoji[:,:,3]/255.0) + img[y:y+h, x:x+w, c] * (1.0 - emoji[:,:,3]/255.0)\n",
    "    \n",
    "    cv2.imshow('frame',img)\n",
    "    #end here\n",
    "    \n",
    "    # Our operations on the frame come here\n",
    "    #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    #cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
